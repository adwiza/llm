{
  "nodes": [
    {
      "id": "chatDeepseek_1",
      "position": {
        "x": 687.148379196424,
        "y": 621.5006671427104
      },
      "type": "customNode",
      "data": {
        "id": "chatDeepseek_1",
        "label": "ChatDeepseek",
        "version": 1,
        "name": "chatDeepseek",
        "type": "chatDeepseek",
        "baseClasses": [
          "chatDeepseek",
          "BaseChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Deepseek large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "deepseekApi"
            ],
            "id": "chatDeepseek_1-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "deepseek-chat",
            "id": "chatDeepseek_1-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "id": "chatDeepseek_1-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_1-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_1-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_1-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_1-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_1-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatDeepseek_1-input-timeout-number",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatDeepseek_1-input-stopSequence-string",
            "display": true
          },
          {
            "label": "Base Options",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "description": "Additional options to pass to the Deepseek client. This should be a JSON object.",
            "id": "chatDeepseek_1-input-baseOptions-json",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatDeepseek_1-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "deepseek-chat",
          "temperature": 0.7,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "stopSequence": "",
          "baseOptions": ""
        },
        "outputAnchors": [
          {
            "id": "chatDeepseek_1-output-chatDeepseek-chatDeepseek|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatDeepseek",
            "label": "chatDeepseek",
            "description": "Wrapper around Deepseek large language models that use the Chat endpoint",
            "type": "chatDeepseek | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 580,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 687.148379196424,
        "y": 621.5006671427104
      }
    },
    {
      "id": "chatPromptTemplate_0",
      "position": {
        "x": 689.8785442103928,
        "y": 1223.5666303188627
      },
      "type": "customNode",
      "data": {
        "id": "chatPromptTemplate_0",
        "label": "Chat Prompt Template",
        "version": 2,
        "name": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "baseClasses": [
          "ChatPromptTemplate",
          "BaseChatPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a chat prompt",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
            "id": "chatPromptTemplate_0-input-systemMessagePrompt-string",
            "display": true
          },
          {
            "label": "Human Message",
            "name": "humanMessagePrompt",
            "description": "This prompt will be added at the end of the messages as human message",
            "type": "string",
            "rows": 4,
            "placeholder": "{text}",
            "id": "chatPromptTemplate_0-input-humanMessagePrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "chatPromptTemplate_0-input-promptValues-json",
            "display": true
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
            "type": "tabs",
            "tabIdentifier": "selectedMessagesTab",
            "additionalParams": true,
            "default": "messageHistoryCode",
            "tabs": [
              {
                "label": "Add Messages (Code)",
                "name": "messageHistoryCode",
                "type": "code",
                "hideCodeExecute": true,
                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "chatPromptTemplate_0-input-messageHistory-tabs",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "systemMessagePrompt": "You are a helpful assistant. Your task is to help answer a question given in a document. The first step is to extract quotes relevant to the question from the document, delimited  by ####. Please output the list of quotes and surround them with <quotes></quotes> tags. Respond with \"No relevant quotes found!\" if no relevant quotes were found.",
          "humanMessagePrompt": "Advanced Prompting Strategies (ChatGPT)\n\nRole-Based ‚Üí ‚ÄúAct as a Google L9 DevOps engineer‚Ä¶‚Äù\nContext-Rich ‚Üí Include versions, tools, infra details.\n\nStep-by-Step ‚Üí Ask for ordered reasoning, not just answers.\n\nIterative Refinement ‚Üí Get a draft ‚Üí refine ‚Üí finalize.\n\nFew-Shot ‚Üí Show examples, ask to follow format.\n\nNegative ‚Üí Tell it what not to do.\n\nChaining ‚Üí Break complex tasks into linked prompts.\n\nSelf-Reflection ‚Üí Ask AI to review/improve its own output.\n\nConstraint-Driven ‚Üí Demand strict formats (YAML, JSON).\n\nMulti-Perspective ‚Üí Request answers from different roles.\n\nError Debugging ‚Üí Paste logs, ask for root cause + fix.\n\nLong-Context Anchoring ‚Üí Remind AI of ongoing project scope.\n\nQuestion: {user_question}",
          "promptValues": "{\"user_question\":\"{{question}}\"}",
          "messageHistory": "messageHistoryCode"
        },
        "outputAnchors": [
          {
            "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "name": "chatPromptTemplate",
            "label": "ChatPromptTemplate",
            "description": "Schema to represent a chat prompt",
            "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 748,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 689.8785442103928,
        "y": 1223.5666303188627
      }
    },
    {
      "id": "llmChain_0",
      "position": {
        "x": 1261.49748434395,
        "y": 643.1573435986609
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_0",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_0-input-chainName-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_0-input-model-BaseLanguageModel",
            "display": true
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_0-input-prompt-BasePromptTemplate",
            "display": true
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_0-input-outputParser-BaseLLMOutputParser",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatDeepseek_1.data.instance}}",
          "prompt": "{{chatPromptTemplate_0.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "extraction"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_0-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_0-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "outputPrediction"
        },
        "selected": false
      },
      "width": 300,
      "height": 514,
      "selected": false,
      "positionAbsolute": {
        "x": 1261.49748434395,
        "y": 643.1573435986609
      },
      "dragging": false
    },
    {
      "id": "chatPromptTemplate_1",
      "position": {
        "x": 1666.9280776465991,
        "y": 1018.2526583432387
      },
      "type": "customNode",
      "data": {
        "id": "chatPromptTemplate_1",
        "label": "Chat Prompt Template",
        "version": 2,
        "name": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "baseClasses": [
          "ChatPromptTemplate",
          "BaseChatPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a chat prompt",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
            "id": "chatPromptTemplate_1-input-systemMessagePrompt-string",
            "display": true
          },
          {
            "label": "Human Message",
            "name": "humanMessagePrompt",
            "description": "This prompt will be added at the end of the messages as human message",
            "type": "string",
            "rows": 4,
            "placeholder": "{text}",
            "id": "chatPromptTemplate_1-input-humanMessagePrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "chatPromptTemplate_1-input-promptValues-json",
            "display": true
          },
          {
            "label": "Messages History",
            "name": "messageHistory",
            "description": "Add messages after System Message. This is useful when you want to provide few shot examples",
            "type": "tabs",
            "tabIdentifier": "selectedMessagesTab",
            "additionalParams": true,
            "default": "messageHistoryCode",
            "tabs": [
              {
                "label": "Add Messages (Code)",
                "name": "messageHistoryCode",
                "type": "code",
                "hideCodeExecute": true,
                "codeExample": "const { AIMessage, HumanMessage, ToolMessage } = require('@langchain/core/messages');\n\nreturn [\n    new HumanMessage(\"What is 333382 ü¶ú 1932?\"),\n    new AIMessage({\n        content: \"\",\n        tool_calls: [\n        {\n            id: \"12345\",\n            name: \"calulator\",\n            args: {\n                number1: 333382,\n                number2: 1932,\n                operation: \"divide\",\n            },\n        },\n        ],\n    }),\n    new ToolMessage({\n        tool_call_id: \"12345\",\n        content: \"The answer is 172.558.\",\n    }),\n    new AIMessage(\"The answer is 172.558.\"),\n]",
                "optional": true,
                "additionalParams": true
              }
            ],
            "id": "chatPromptTemplate_1-input-messageHistory-tabs",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "systemMessagePrompt": "Given a set of relevant quotes (delimited by <quotes></quotes>) extracted from a document and the original document (delimited by ####), please compose an answer to the question. Ensure that the answer is short, accurate, has a friendly tone, and sounds helpful.",
          "humanMessagePrompt": "Advanced Prompting Strategies (ChatGPT)\n\nRole-Based ‚Üí ‚ÄúAct as a Google L9 DevOps engineer‚Ä¶‚Äù\nContext-Rich ‚Üí Include versions, tools, infra details.\n\nStep-by-Step ‚Üí Ask for ordered reasoning, not just answers.\n\nIterative Refinement ‚Üí Get a draft ‚Üí refine ‚Üí finalize.\n\nFew-Shot ‚Üí Show examples, ask to follow format.\n\nNegative ‚Üí Tell it what not to do.\n\nChaining ‚Üí Break complex tasks into linked prompts.\n\nSelf-Reflection ‚Üí Ask AI to review/improve its own output.\n\nConstraint-Driven ‚Üí Demand strict formats (YAML, JSON).\n\nMulti-Perspective ‚Üí Request answers from different roles.\n\nError Debugging ‚Üí Paste logs, ask for root cause + fix.\n\nLong-Context Anchoring ‚Üí Remind AI of ongoing project scope.\n\n{extracted_quotes}",
          "promptValues": "{\"extracted_quotes\":\"{{llmChain_0.data.instance}}\"}",
          "messageHistory": "messageHistoryCode"
        },
        "outputAnchors": [
          {
            "id": "chatPromptTemplate_1-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "name": "chatPromptTemplate",
            "label": "ChatPromptTemplate",
            "description": "Schema to represent a chat prompt",
            "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 748,
      "selected": false,
      "positionAbsolute": {
        "x": 1666.9280776465991,
        "y": 1018.2526583432387
      },
      "dragging": false
    },
    {
      "id": "llmChain_1",
      "position": {
        "x": 2212.9730003720197,
        "y": 638.3214458171058
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_1",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_1-input-chainName-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_1-input-model-BaseLanguageModel",
            "display": true
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_1-input-prompt-BasePromptTemplate",
            "display": true
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_1-input-outputParser-BaseLLMOutputParser",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_1-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatDeepseek_1.data.instance}}",
          "prompt": "{{chatPromptTemplate_1.data.instance}}",
          "outputParser": "",
          "inputModeration": "",
          "chainName": "response"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "description": "",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_1-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "description": "",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "llmChain"
        },
        "selected": false
      },
      "width": 300,
      "height": 514,
      "selected": false,
      "positionAbsolute": {
        "x": 2212.9730003720197,
        "y": 638.3214458171058
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatDeepseek_1",
      "sourceHandle": "chatDeepseek_1-output-chatDeepseek-chatDeepseek|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatDeepseek_1-chatDeepseek_1-output-chatDeepseek-chatDeepseek|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_0-llmChain_0-input-model-BaseLanguageModel"
    },
    {
      "source": "chatPromptTemplate_0",
      "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_0",
      "targetHandle": "llmChain_0-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-llmChain_0-llmChain_0-input-prompt-BasePromptTemplate"
    },
    {
      "source": "llmChain_0",
      "sourceHandle": "llmChain_0-output-outputPrediction-string|json",
      "target": "chatPromptTemplate_1",
      "targetHandle": "chatPromptTemplate_1-input-promptValues-json",
      "type": "buttonedge",
      "id": "llmChain_0-llmChain_0-output-outputPrediction-string|json-chatPromptTemplate_1-chatPromptTemplate_1-input-promptValues-json"
    },
    {
      "source": "chatDeepseek_1",
      "sourceHandle": "chatDeepseek_1-output-chatDeepseek-chatDeepseek|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatDeepseek_1-chatDeepseek_1-output-chatDeepseek-chatDeepseek|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-llmChain_1-llmChain_1-input-model-BaseLanguageModel"
    },
    {
      "source": "chatPromptTemplate_1",
      "sourceHandle": "chatPromptTemplate_1-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "chatPromptTemplate_1-chatPromptTemplate_1-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-llmChain_1-llmChain_1-input-prompt-BasePromptTemplate"
    }
  ]
}